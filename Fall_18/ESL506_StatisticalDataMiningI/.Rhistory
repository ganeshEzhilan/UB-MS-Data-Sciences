new.output <- compute(nn, covariate = testData[,1:57])
predicted_class_new_data <- round(new.output$net.result)
cat('Test error without any outliers : ', mean(predicted_class_new_data != testData$spam),'\n')
#2.390700435355
trainDataOutLier = trainData
trainDataOutLier[1,4] = 300
nn <- neuralnet(formula , data = trainDataOutLier, hidden = 1, act.fct = "logistic",err.fct = 'sse', linear.output = FALSE)
new.output <- compute(nn, covariate = testData[,1:57])
predicted_class_new_data <- round(new.output$net.result)
cat('Test error when a value at 0.0628 was changed to 300 : ',mean(predicted_class_new_data != testData$spam),'\n')
trainDataOutLier[1,4] = 100
nn <- neuralnet(formula , data = trainDataOutLier, hidden = 1, act.fct = "logistic",err.fct = 'sse', linear.output = FALSE)
new.output <- compute(nn, covariate = testData[,1:57])
predicted_class_new_data <- round(new.output$net.result)
cat('Test error when that outlier is moved to 100 :', mean(predicted_class_new_data != testData$spam),'\n')
trainDataOutLier[1,4] = 30
nn <- neuralnet(formula , data = trainDataOutLier, hidden = 1, act.fct = "logistic",err.fct = 'sse', linear.output = FALSE)
new.output <- compute(nn, covariate = testData[,1:57])
predicted_class_new_data <- round(new.output$net.result)
cat('Test error when that outlier is moved closer to 30: ', mean(predicted_class_new_data != testData$spam),'\n')
trainDataOutLier[1,4] = 3
nn <- neuralnet(formula , data = trainDataOutLier, hidden = 1, act.fct = "logistic",err.fct = 'sse', linear.output = FALSE)
new.output <- compute(nn, covariate = testData[,1:57])
predicted_class_new_data <- round(new.output$net.result)
cat('Test error when the outlier is moved to 3: ', mean(predicted_class_new_data != testData$spam),'\n')
trainDataOutLier[1,4] = -0.06278457691
nn <- neuralnet(formula , data = trainDataOutLier, hidden = 1, act.fct = "logistic",err.fct = 'sse', linear.output = FALSE)
new.output <- compute(nn, covariate = testData[,1:57])
predicted_class_new_data <- round(new.output$net.result)
cat('Test error when the outlier is replaced with original value: ', mean(predicted_class_new_data != testData$spam),'\n')
###Q 5 ##################
#####################################
library(uskewFactors)
install.packages('uskewFactors')
###Q 5 ##################
#####################################
library(uskewFactors)
#Plotting the diaganosis plots
install.packages("devtools")
library(devtools)
install_github("vqv/ggbiplot")
library(ggbiplot)
data("banknote")
bank_gen=subset(banknote,banknote$Y==0)
bank_fake=subset(banknote,banknote$Y==1)
genuine_PCA=prcomp(bank_gen[,c(2:7)],center = TRUE)
fake_PCA=prcomp(bank_fake[,c(2:7)],center = TRUE)
combined_PCA=prcomp(banknote[,c(2:7)],center = TRUE)
summary(genuine_PCA) #PC till the 4th one accounts for 92% variance
summary(fake_PCA) #PC till the 3rd one accounts for 90%
summary(combined_PCA) #PC till the 3rd one accounts for 93%
#selecting PCs using variance dip
plot(genuine_PCA,type = "l", main = "Genuine PCA")
plot(fake_PCA, type = "l", main = "Fake PCA")
knitr::opts_chunk$set(echo = FALSE)
rm(list = ls())
library(ElemStatLearn)
library(randomForest)
library(ggplot2)
library(neuralnet)
library(gam)
setwd("/Users/abhishekkumar/Documents/MS_UB/Fall_18/ESL506_StatisticalDataMiningI/HW5")
###Q 5 ##################
#####################################
library(uskewFactors)
#Plotting the diaganosis plots
#install.packages("devtools")
library(devtools)
#install_github("vqv/ggbiplot")
library(ggbiplot)
data("banknote")
bank_gen=subset(banknote,banknote$Y==0)
bank_fake=subset(banknote,banknote$Y==1)
genuine_PCA=prcomp(bank_gen[,c(2:7)],center = TRUE)
fake_PCA=prcomp(bank_fake[,c(2:7)],center = TRUE)
combined_PCA=prcomp(banknote[,c(2:7)],center = TRUE)
summary(genuine_PCA) #PC till the 4th one accounts for 92% variance
summary(fake_PCA) #PC till the 3rd one accounts for 90%
summary(combined_PCA) #PC till the 3rd one accounts for 93%
#selecting PCs using variance dip
plot(genuine_PCA,type = "l", main = "Genuine PCA")
plot(fake_PCA, type = "l", main = "Fake PCA")
plot(combined_PCA, type = "l", main = "Combined PCA")
#Analyzing loadings
print(genuine_PCA)
print(fake_PCA)
print(combined_PCA)
print(combined_PCA)
summary(genuine_PCA)
rm (list=ls())
library(ISLR)
library(e1071)
data(OJ)
attach(OJ)
test_indis <- sample(1:nrow(OJ), 0.35*nrow(OJ))
test_oj <- OJ[test_indis,]
train_oj <- OJ[-test_indis,]
test_error_linear <- c()
train_error_linear <- c()
####  a  ####
#######  SVM with a Linear Kernel  ########
for (i in c(0.01,0.1, 1, 5, 10)){
linear_oj_svm <- tune(svm, Purchase ~ .,data = train_oj, kernel = "linear",ranges = list(cost = i))
best_model_oj <- linear_oj_svm$best.model
### predict test data ###
y_hat <- predict(best_model_oj, newdata = test_oj)
y_true <- test_oj$Purchase
test_err <- length(which(y_true != y_hat))/length(y_true)
test_error_linear<-c(test_error_linear,test_err)
y_hat <- predict(best_model_oj, newdata = train_oj)
y_true <- train_oj$Purchase
train_err <- length(which(y_true != y_hat))/length(y_true)
train_error_linear<-c(train_error_linear,train_err)
}
test_error_linear
train_error_linear
### Plotting ###
upper.lr = max(test_error_linear, train_error_linear)
lower.lr = min(test_error_linear, train_error_linear)
plot(train_error_linear, type = "o", lty = 2, col = "black", ylim = c(lower.lr -1, upper.lr +1) , xlab = "cost", ylab = "error", main = "Test and Training Errors")
lines(test_error_linear, type = "o", lty = 1, col = "red")
legend("topright", c("training", "test"), lty = c(2,1), col = c("black","red"))
##########  SVM with a Radial Kernel  ############
train_error_radial <- c()
test_error_radial<- c()
for (i in c(0.01,0.1, 1, 5, 10)){
radial_oj_svm <- tune(svm, Purchase ~ .,data = train_oj, kernel = "radial",ranges = list(cost = i))
best_model_oj <- radial_oj_svm$best.model
best_model_oj
### predict test data ###
y_hat <- predict(best_model_oj, newdata = test_oj)
y_true <- test_oj$Purchase
test_err <- length(which(y_true != y_hat))/length(y_true)
test_error_radial<-c(test_error_radial,test_err)
y_hat <- predict(best_model_oj, newdata = train_oj)
y_true <- train_oj$Purchase
train_err <- length(which(y_true != y_hat))/length(y_true)
train_error_radial<-c(train_error_radial,train_err)
}
test_error_radial
train_error_radial
### Plotting ###
upper.lr = max(test_error_radial, train_error_radial)
lower.lr = min(test_error_radial, train_error_radial)
plot(train_error_radial, type = "o", lty = 2, col = "blue", ylim = c(lower.lr -1, upper.lr +1) , xlab = "cost", ylab = "error", main = "Test and Training Errors for Radial Kernel")
lines(test_error_radial, type = "o", lty = 1, col = "red")
legend("topright", c("training", "test"), lty = c(2,1), col = c("blue","red"))
##########  SVM with a Polynimal Kernel  ############
train_error_poly <- c()
test_error_poly<- c()
for (i in c(0.01,0.1, 1, 5, 10)){
oj.poly.svm <- tune(svm, Purchase ~ .,data = train_oj, degree = 2, kernel = "polynomial",ranges = list(cost = i))
best_model_oj <- oj.poly.svm$best.model
best_model_oj
### predict test data ###
y_hat <- predict(best_model_oj, newdata = test_oj)
y_true <- test_oj$Purchase
test_err <- length(which(y_true != y_hat))/length(y_true)
test_error_poly<-c(test_error_poly,test_err)
y_hat <- predict(best_model_oj, newdata = train_oj)
y_true <- train_oj$Purchase
train_err <- length(which(y_true != y_hat))/length(y_true)
train_error_poly<-c(train_error_poly,train_err)
}
test_error_poly
train_error_poly
### Plotting ###
upper.lr = max(test_error_poly, train_error_poly)
lower.lr = min(test_error_poly, train_error_poly)
plot(train_error_poly, type = "o", lty = 2, col = "orange", ylim = c(lower.lr -1, upper.lr +1) , xlab = "cost", ylab = "error", main = "Test and Training Errors for polynomial Kernel")
lines(test_error_poly, type = "o", lty = 1, col = "blue")
legend("topright", c("training", "test"), lty = c(2,1), col = c("orange","blue"))
which(min(train_error_poly) == train_error_poly)
which(min(train_error_radial) == train_error_radial)
summary(best_model_oj)
summary(linear_oj_svm)
rm (list=ls())
library(ISLR)
library(e1071)
data(OJ)
attach(OJ)
test_indis <- sample(1:nrow(OJ), 0.35*nrow(OJ))
test_oj <- OJ[test_indis,]
train_oj <- OJ[-test_indis,]
test_error_linear <- c()
train_error_linear <- c()
####  a  ####
#######  SVM with a Linear Kernel  ########
for (i in c(0.01,0.1, 1, 5, 10)){
linear_oj_svm <- tune(svm, Purchase ~ .,data = train_oj, kernel = "linear",ranges = list(cost = i))
best_model_oj <- linear_oj_svm$best.model
### predict test data ###
y_hat <- predict(best_model_oj, newdata = test_oj)
y_true <- test_oj$Purchase
test_err <- length(which(y_true != y_hat))/length(y_true)
test_error_linear<-c(test_error_linear,test_err)
y_hat <- predict(best_model_oj, newdata = train_oj)
y_true <- train_oj$Purchase
train_err <- length(which(y_true != y_hat))/length(y_true)
train_error_linear<-c(train_error_linear,train_err)
}
cat('Train error for linear kernal :', train_error_linear)
cat('Test error for linear kernal :', test_error_linear)
### Plotting ###
upper.lr = max(test_error_linear, train_error_linear)
lower.lr = min(test_error_linear, train_error_linear)
plot(train_error_linear, type = "o", lty = 2, col = "black", ylim = c(lower.lr -1, upper.lr +1) , xlab = "cost", ylab = "error", main = "Test and Training Errors")
lines(test_error_linear, type = "o", lty = 1, col = "red")
legend("topright", c("training", "test"), lty = c(2,1), col = c("black","red"))
##########  SVM with a Radial Kernel  ############
train_error_radial <- c()
test_error_radial<- c()
for (i in c(0.01,0.1, 1, 5, 10)){
radial_oj_svm <- tune(svm, Purchase ~ .,data = train_oj, kernel = "radial",ranges = list(cost = i))
best_model_oj <- radial_oj_svm$best.model
best_model_oj
### predict test data ###
y_hat <- predict(best_model_oj, newdata = test_oj)
y_true <- test_oj$Purchase
test_err <- length(which(y_true != y_hat))/length(y_true)
test_error_radial<-c(test_error_radial,test_err)
y_hat <- predict(best_model_oj, newdata = train_oj)
y_true <- train_oj$Purchase
train_err <- length(which(y_true != y_hat))/length(y_true)
train_error_radial<-c(train_error_radial,train_err)
}
cat('Train error for radial kernal :', train_error_radial)
cat('Test error for radial kernal :', test_error_radial)
### Plotting ###
upper.lr = max(test_error_radial, train_error_radial)
lower.lr = min(test_error_radial, train_error_radial)
plot(train_error_radial, type = "o", lty = 2, col = "blue", ylim = c(lower.lr -1, upper.lr +1) , xlab = "cost", ylab = "error", main = "Test and Training Errors for Radial Kernel")
lines(test_error_radial, type = "o", lty = 1, col = "red")
legend("topright", c("training", "test"), lty = c(2,1), col = c("blue","red"))
##########  SVM with a Polynimal Kernel  ############
train_error_poly <- c()
test_error_poly<- c()
for (i in c(0.01,0.1, 1, 5, 10)){
oj.poly.svm <- tune(svm, Purchase ~ .,data = train_oj, degree = 2, kernel = "polynomial",ranges = list(cost = i))
best_model_oj <- oj.poly.svm$best.model
best_model_oj
### predict test data ###
y_hat <- predict(best_model_oj, newdata = test_oj)
y_true <- test_oj$Purchase
test_err <- length(which(y_true != y_hat))/length(y_true)
test_error_poly<-c(test_error_poly,test_err)
y_hat <- predict(best_model_oj, newdata = train_oj)
y_true <- train_oj$Purchase
train_err <- length(which(y_true != y_hat))/length(y_true)
train_error_poly<-c(train_error_poly,train_err)
}
cat('Train error for polynomial kernal :', train_error_poly)
cat('Test error for polynomial kernal :', test_error_poly)
### Plotting ###
upper.lr = max(test_error_poly, train_error_poly)
lower.lr = min(test_error_poly, train_error_poly)
plot(train_error_poly, type = "o", lty = 2, col = "orange", ylim = c(lower.lr -1, upper.lr +1) , xlab = "cost", ylab = "error", main = "Test and Training Errors for polynomial Kernel")
lines(test_error_poly, type = "o", lty = 1, col = "blue")
legend("topright", c("training", "test"), lty = c(2,1), col = c("orange","blue"))
rm (list=ls())
library(ISLR)
library(e1071)
data(OJ)
attach(OJ)
test_indis <- sample(1:nrow(OJ), 0.35*nrow(OJ))
test_oj <- OJ[test_indis,]
train_oj <- OJ[-test_indis,]
test_error_linear <- c()
train_error_linear <- c()
####  a  ####
#######  SVM with a Linear Kernel  ########
for (i in c(0.01,0.1, 1, 5, 10)){
linear_oj_svm <- tune(svm, Purchase ~ .,data = train_oj, kernel = "linear",ranges = list(cost = i))
best_model_oj <- linear_oj_svm$best.model
### predict test data ###
y_hat <- predict(best_model_oj, newdata = test_oj)
y_true <- test_oj$Purchase
test_err <- length(which(y_true != y_hat))/length(y_true)
test_error_linear<-c(test_error_linear,test_err)
y_hat <- predict(best_model_oj, newdata = train_oj)
y_true <- train_oj$Purchase
train_err <- length(which(y_true != y_hat))/length(y_true)
train_error_linear<-c(train_error_linear,train_err)
}
cat('Train error for linear kernal :', train_error_linear)
cat('Test error for linear kernal :', test_error_linear)
### Plotting ###
upper.lr = max(test_error_linear, train_error_linear)
lower.lr = min(test_error_linear, train_error_linear)
plot(train_error_linear, type = "o", lty = 2, col = "black", ylim = c(lower.lr -1, upper.lr +1) , xlab = "cost", ylab = "error", main = "Test and Training Errors")
lines(test_error_linear, type = "o", lty = 1, col = "red")
legend("topright", c("training", "test"), lty = c(2,1), col = c("black","red"))
##########  SVM with a Radial Kernel  ############
train_error_radial <- c()
test_error_radial<- c()
for (i in c(0.01,0.1, 1, 5, 10)){
radial_oj_svm <- tune(svm, Purchase ~ .,data = train_oj, kernel = "radial",ranges = list(cost = i))
best_model_oj <- radial_oj_svm$best.model
best_model_oj
### predict test data ###
y_hat <- predict(best_model_oj, newdata = test_oj)
y_true <- test_oj$Purchase
test_err <- length(which(y_true != y_hat))/length(y_true)
test_error_radial<-c(test_error_radial,test_err)
y_hat <- predict(best_model_oj, newdata = train_oj)
y_true <- train_oj$Purchase
train_err <- length(which(y_true != y_hat))/length(y_true)
train_error_radial<-c(train_error_radial,train_err)
}
cat('Train error for radial kernal :', train_error_radial)
cat('Test error for radial kernal :', test_error_radial)
### Plotting ###
upper.lr = max(test_error_radial, train_error_radial)
lower.lr = min(test_error_radial, train_error_radial)
plot(train_error_radial, type = "o", lty = 2, col = "blue", ylim = c(lower.lr -1, upper.lr +1) , xlab = "cost", ylab = "error", main = "Test and Training Errors for Radial Kernel")
lines(test_error_radial, type = "o", lty = 1, col = "red")
legend("topright", c("training", "test"), lty = c(2,1), col = c("blue","red"))
##########  SVM with a Polynimal Kernel  ############
train_error_poly <- c()
test_error_poly<- c()
for (i in c(0.01,0.1, 1, 5, 10)){
oj.poly.svm <- tune(svm, Purchase ~ .,data = train_oj, degree = 2, kernel = "polynomial",ranges = list(cost = i))
best_model_oj <- oj.poly.svm$best.model
best_model_oj
### predict test data ###
y_hat <- predict(best_model_oj, newdata = test_oj)
y_true <- test_oj$Purchase
test_err <- length(which(y_true != y_hat))/length(y_true)
test_error_poly<-c(test_error_poly,test_err)
y_hat <- predict(best_model_oj, newdata = train_oj)
y_true <- train_oj$Purchase
train_err <- length(which(y_true != y_hat))/length(y_true)
train_error_poly<-c(train_error_poly,train_err)
}
cat('Train error for polynomial kernal :', train_error_poly)
cat('Test error for polynomial kernal :', test_error_poly)
### Plotting ###
upper.lr = max(test_error_poly, train_error_poly)
lower.lr = min(test_error_poly, train_error_poly)
plot(train_error_poly, type = "o", lty = 2, col = "orange", ylim = c(lower.lr -1, upper.lr +1) , xlab = "cost", ylab = "error", main = "Test and Training Errors for polynomial Kernel")
lines(test_error_poly, type = "o", lty = 1, col = "blue")
legend("topright", c("training", "test"), lty = c(2,1), col = c("orange","blue"))
rm (list=ls())
library(ISLR)
library(e1071)
data(OJ)
attach(OJ)
test_indis <- sample(1:nrow(OJ), 0.35*nrow(OJ))
test_oj <- OJ[test_indis,]
train_oj <- OJ[-test_indis,]
test_error_linear <- c()
train_error_linear <- c()
####  a  ####
#######  SVM with a Linear Kernel  ########
for (i in c(0.01,0.1, 1, 5, 10)){
linear_oj_svm <- tune(svm, Purchase ~ .,data = train_oj, kernel = "linear",ranges = list(cost = i))
best_model_oj <- linear_oj_svm$best.model
### predict test data ###
y_hat <- predict(best_model_oj, newdata = test_oj)
y_true <- test_oj$Purchase
test_err <- length(which(y_true != y_hat))/length(y_true)
test_error_linear<-c(test_error_linear,test_err)
y_hat <- predict(best_model_oj, newdata = train_oj)
y_true <- train_oj$Purchase
train_err <- length(which(y_true != y_hat))/length(y_true)
train_error_linear<-c(train_error_linear,train_err)
}
cat('Train error for linear kernal :', train_error_linear,'\n')
cat('Test error for linear kernal :', test_error_linear,'\n')
### Plotting ###
upper.lr = max(test_error_linear, train_error_linear)
lower.lr = min(test_error_linear, train_error_linear)
plot(train_error_linear, type = "o", lty = 2, col = "black", ylim = c(lower.lr -1, upper.lr +1) , xlab = "cost", ylab = "error", main = "Test and Training Errors")
lines(test_error_linear, type = "o", lty = 1, col = "red")
legend("topright", c("training", "test"), lty = c(2,1), col = c("black","red"))
##########  SVM with a Radial Kernel  ############
train_error_radial <- c()
test_error_radial<- c()
for (i in c(0.01,0.1, 1, 5, 10)){
radial_oj_svm <- tune(svm, Purchase ~ .,data = train_oj, kernel = "radial",ranges = list(cost = i))
best_model_oj <- radial_oj_svm$best.model
best_model_oj
### predict test data ###
y_hat <- predict(best_model_oj, newdata = test_oj)
y_true <- test_oj$Purchase
test_err <- length(which(y_true != y_hat))/length(y_true)
test_error_radial<-c(test_error_radial,test_err)
y_hat <- predict(best_model_oj, newdata = train_oj)
y_true <- train_oj$Purchase
train_err <- length(which(y_true != y_hat))/length(y_true)
train_error_radial<-c(train_error_radial,train_err)
}
cat('Train error for radial kernal :', train_error_radial,'\n')
cat('Test error for radial kernal :', test_error_radial,'\n')
### Plotting ###
upper.lr = max(test_error_radial, train_error_radial)
lower.lr = min(test_error_radial, train_error_radial)
plot(train_error_radial, type = "o", lty = 2, col = "blue", ylim = c(lower.lr -1, upper.lr +1) , xlab = "cost", ylab = "error", main = "Test and Training Errors for Radial Kernel")
lines(test_error_radial, type = "o", lty = 1, col = "red")
legend("topright", c("training", "test"), lty = c(2,1), col = c("blue","red"))
##########  SVM with a Polynimal Kernel  ############
train_error_poly <- c()
test_error_poly<- c()
for (i in c(0.01,0.1, 1, 5, 10)){
oj.poly.svm <- tune(svm, Purchase ~ .,data = train_oj, degree = 2, kernel = "polynomial",ranges = list(cost = i))
best_model_oj <- oj.poly.svm$best.model
best_model_oj
### predict test data ###
y_hat <- predict(best_model_oj, newdata = test_oj)
y_true <- test_oj$Purchase
test_err <- length(which(y_true != y_hat))/length(y_true)
test_error_poly<-c(test_error_poly,test_err)
y_hat <- predict(best_model_oj, newdata = train_oj)
y_true <- train_oj$Purchase
train_err <- length(which(y_true != y_hat))/length(y_true)
train_error_poly<-c(train_error_poly,train_err)
}
cat('Train error for polynomial kernal :', train_error_poly,'\n')
cat('Test error for polynomial kernal :', test_error_poly,'\n')
### Plotting ###
upper.lr = max(test_error_poly, train_error_poly)
lower.lr = min(test_error_poly, train_error_poly)
plot(train_error_poly, type = "o", lty = 2, col = "orange", ylim = c(lower.lr -1, upper.lr +1) , xlab = "cost", ylab = "error", main = "Test and Training Errors for polynomial Kernel")
lines(test_error_poly, type = "o", lty = 1, col = "blue")
legend("topright", c("training", "test"), lty = c(2,1), col = c("orange","blue"))
?plot
rm (list=ls())
library(ISLR)
library(e1071)
data(OJ)
attach(OJ)
test_indis <- sample(1:nrow(OJ), 0.35*nrow(OJ))
test_oj <- OJ[test_indis,]
train_oj <- OJ[-test_indis,]
test_error_linear <- c()
train_error_linear <- c()
####  a  ####
#######  SVM with a Linear Kernel  ########
for (i in c(0.01,0.1, 1, 5, 10)){
linear_oj_svm <- tune(svm, Purchase ~ .,data = train_oj, kernel = "linear",ranges = list(cost = i))
best_model_oj <- linear_oj_svm$best.model
### predict test data ###
y_hat <- predict(best_model_oj, newdata = test_oj)
y_true <- test_oj$Purchase
test_err <- length(which(y_true != y_hat))/length(y_true)
test_error_linear<-c(test_error_linear,test_err)
y_hat <- predict(best_model_oj, newdata = train_oj)
y_true <- train_oj$Purchase
train_err <- length(which(y_true != y_hat))/length(y_true)
train_error_linear<-c(train_error_linear,train_err)
}
cat('ERROR, INCREASING ORDER OF COST \n')
cat('Train error for linear kernal :', train_error_linear,'\n')
cat('Test error for linear kernal :', test_error_linear,'\n')
### Plotting ###
upper.lr = max(test_error_linear, train_error_linear)
lower.lr = min(test_error_linear, train_error_linear)
plot(train_error_linear, type = "o", lty = 2, col = "black", ylim = c(lower.lr -1, upper.lr +1) , xlab = "cost", ylab = "error", main = "Test and Training Errors")
lines(test_error_linear, type = "o", lty = 1, col = "red")
legend("topright", c("training", "test"), lty = c(2,1), col = c("black","red"))
##########  SVM with a Radial Kernel  ############
train_error_radial <- c()
test_error_radial<- c()
for (i in c(0.01,0.1, 1, 5, 10)){
radial_oj_svm <- tune(svm, Purchase ~ .,data = train_oj, kernel = "radial",ranges = list(cost = i))
best_model_oj <- radial_oj_svm$best.model
best_model_oj
### predict test data ###
y_hat <- predict(best_model_oj, newdata = test_oj)
y_true <- test_oj$Purchase
test_err <- length(which(y_true != y_hat))/length(y_true)
test_error_radial<-c(test_error_radial,test_err)
y_hat <- predict(best_model_oj, newdata = train_oj)
y_true <- train_oj$Purchase
train_err <- length(which(y_true != y_hat))/length(y_true)
train_error_radial<-c(train_error_radial,train_err)
}
cat('ERROR, INCREASING ORDER OF COST \n')
cat('Train error for radial kernal :', train_error_radial,'\n')
cat('Test error for radial kernal :', test_error_radial,'\n')
### Plotting ###
upper.lr = max(test_error_radial, train_error_radial)
lower.lr = min(test_error_radial, train_error_radial)
plot(train_error_radial, type = "o", lty = 2, col = "blue", ylim = c(lower.lr -1, upper.lr +1) , xlab = "cost", ylab = "error", main = "Test and Training Errors for Radial Kernel")
lines(test_error_radial, type = "o", lty = 1, col = "red")
legend("topright", c("training", "test"), lty = c(2,1), col = c("blue","red"))
##########  SVM with a Polynimal Kernel  ############
train_error_poly <- c()
test_error_poly<- c()
for (i in c(0.01,0.1, 1, 5, 10)){
oj.poly.svm <- tune(svm, Purchase ~ .,data = train_oj, degree = 2, kernel = "polynomial",ranges = list(cost = i))
best_model_oj <- oj.poly.svm$best.model
best_model_oj
### predict test data ###
y_hat <- predict(best_model_oj, newdata = test_oj)
y_true <- test_oj$Purchase
test_err <- length(which(y_true != y_hat))/length(y_true)
test_error_poly<-c(test_error_poly,test_err)
y_hat <- predict(best_model_oj, newdata = train_oj)
y_true <- train_oj$Purchase
train_err <- length(which(y_true != y_hat))/length(y_true)
train_error_poly<-c(train_error_poly,train_err)
}
cat('ERROR, INCREASING ORDER OF COST \n')
cat('Train error for polynomial kernal :', train_error_poly,'\n')
cat('Test error for polynomial kernal :', test_error_poly,'\n')
### Plotting ###
upper.lr = max(test_error_poly, train_error_poly)
lower.lr = min(test_error_poly, train_error_poly)
plot(train_error_poly,c(0.01,0.1, 1, 5, 10), type = "o", lty = 2, col = "orange", ylim = c(lower.lr -1, upper.lr +1) , xlab = "cost", ylab = "error", main = "Test and Training Errors for polynomial Kernel")
lines(test_error_poly, type = "o", lty = 1, col = "blue")
legend("topright", c("training", "test"), lty = c(2,1), col = c("orange","blue"))
